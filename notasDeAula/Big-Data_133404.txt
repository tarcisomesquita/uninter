A01-P01
sumário

A01-P02
grande quantidade de dados
  documento de analógico para digital
  novos dispositivos (celular, internet das coisas)

Lei de Moore
  A capacidade de processamento dobra a cada 18 meses

A01-P03
Volume (data size), Velocity (speed of change), Variety (different forms of data source), Veracity (uncertainty of data)
Valor, Validade, Vulnerabilidade, Volatilidade, Visualização

Big data coleta dados que pode extrair informações

A01-P04
fontes: dados internos, datificação, dados de sensores, dados de fontes externas (internet)
armazenamento: escabilidade, disponibilidade, flexibilidade (suportar diferentes formatos)

NoSQL
chave-valor: chaves são indexadas, valor não.

A01-P05
escabilidade vertical (melhorar hardware) e horizontal (aumentar a quantidade de máquinas, que podem estar em diferentes lugares)

Hadoop
baixo custo, escabilidade, tolerância a falhas (partição) (pode ser de rede), balanceamento de carga, comunicação entre máquinas, alocação de máquinas

HDFS (Hadoop distributed file system)
MapReduce (processamento distribuido)

baixa latência, consistência, alta disponibilidade

spark core: MapReduce
GraphX: processamento de grafos
Spark SQL: 
MLib: machine learning

componentes spark: driver program, cluster manager, workers

A01-P06
análise de dados: como processar e extrair informações com valor

entendimento do negócio, compreender os dados, preparação dos dados, modelagem dos dados, avaliação do modelo, utilização do modelo

visualização exploratória, visualização explanatória

A07.mp4
cloudera.com
HDP (Hortonworks Data Platform)
image virtual box
change root password

Ambari

user maria_dev, admin

views: Files, Hive, Pig, Tez, Workflow

Files: sistema de arquivo
Hive: importar dados, query
Pig: escrever scripts
Tez: grafos, visualização
Workflow: monitorar fluxos

A02-P01
Sumário

A02-P02
ecossistema hadoop: módulos

hadoop é uma plataforma de software open source para o armazenamento e processamento distribuído de conjunto de dados muito grandes em cluster de computadores.

Esquema de módulos
HDFS (sistema de arquivos), YARN (gerenciador de recursos do cluster), MapReduce (distribui o processamento)

tem um nó que gerencia os outros

A02-P03
HDFS
Os dados são distribuidos pelo cluster
tolerância a partição

blocos de 128 MiB são replicados

data node, name node (nome dos arquivos, quais nodes tem réplica)
um client node, um name node, vários data node

esquema de escrita de arquivos

A02-P04
MapReduce

entrada de dados > mapper > conjunto de chave-valor > agrupa valores com a mesma chave

cliente > YARN > Node Manager (aplicação mestre distribui para aplicações MapReducer)

A02-P05
Alternativas ao MapReducer
MapReduce é dificil fazer SQL

Pig é muito semelhante ao SQL, o Pig Latin, ainda usa o MapReduce
relação > tabela
tupla > registro (linha)
campo > coluna

tem join

Tez, substitui totalmente o MapReduce
usa grafos acíclicos e lê menos o FDFS

A02-P06
Gerenciamento de cluster
YARN

premeira versão do hadoop tinha apenas os módulos MapReduce e HDFS. Depois acrescentaram o YARN antes do MapReduce.

é um gerenciador de recursos no nó mestre. Ele distribui trabalho para os demais nós.

ZooKeeper
garante a alta disponibilidade caso tenha uma partição

vários servidores ZooKeeper e vários Clientes ZooKeepers (em nós trabalhadores)

Oozie
também usa grafos acíclicos

A08
HDFS
https://grouplens.org/datasets/movielens/100k/
MovieLens dataset

importou arquivo

hadoop fs -ls
hadoop fs -copyFromLocal u.data /user/maria_dev/

do HDFS para o computador
hadoop fs -copyToLocal u.data

hadoop fs -rm u.data

hadoop fs
mostra lista de comandos

Oozie

A03-P01
Banco de dados
Sumário

A03-P02
Hive
Faz consultas

HiveQL
Opera em MapReduce ou Tez

schema on read

A03-P03
Integração a banco de dados relacionais: Sqoop

sqoop import --connect jdbc:mysql://localhost/foobar --driver com.mysql.jdbc.Driver --table foo
--hive import
--incremental

sqoop export --connect jdbc:mysql://localhost/foobar --driver com.mysql.jdbc.Driver --table exported_foo --export-dir /app/hive/warehouse/foo --input-fields-teminated-by '\001'

A03-P04
NoSQL
CAP: tolerância a Partição é fixa, portanto escolhe ou Consistência ou Disponibilidade

chave-valor, documentos, colunas, grafos

SGBD: HBase

A03-P05
NoSQL externo

Cassandra
Linguagem CQL
Suporta ACID
Não tem JOIN
Não tem chave estrangeira
Nós distribuidos em forma de anel, sem mestre.

MongoDB (documentos)
JSON
Consistência e Partição, logo pode ficar indisponível, pois tem que retornar dados atuais.

Coleções e documentos
dados embutidos
dado normalizados (faz referência a outro documento)

Servidor primário replica para segundários.

A03-P06
Motores de consulta SQL
Drill: dados em formato JSON, usa SQL, usa ZooKeeper
Phoenix: SQL para HBase, ACID, MapReduce, Spark, Hive, Flume
Presto: SQL para OLAB, projetado pelo Facebook, suporta esquemas relacional e nosql

A09
importa dados e faz consulta

Hive
upload table
u.data
colocou nos nomes das colunas

upload table
u.item
indicou que o separador é |
colocou nos nomes das colunas
colocou o nome da tabela "names"

Query
importou query


HBase
configurou
Pig
conectou pelo shell
hbase shell
criou tabela
consultou
apagou


MySQL
Sqoop
configura uma tabela no MySQL
sqoop import
mostrou os comandos, mas não mostro a prática


Cassandra
Instalou


MongoDB
Instalou

A04-P01
Sumário

Arquitetura Lambda
Ferramentas: Kafka, Flume, Storm, Flink

A04-P02
Processamento de fluxo de dados distribuídos

baixa latência: o processamento é mais rápido que velocidade de entrada de dados

Arquitetura Lambda
- Batch layer: armazena e pré-processa
- Serving layer: disponibiliza os dados da camada anterior
- Speed layer: processa cada dado. Realtime View

A04-P03
Kafka

uma fila de mensagens, um buffer. Baixa latência.
publicação e inscrição, como o dbus no linux

produtor: cria tópico e publica eventos nele
consumidores: se increvem em tópicos

também é usado para processamento de dados
um evento publicado pode ter tempo de duração, ou seja, quanto tempo o Kafka vai guardá-lo esperando clientes

A04-P04
Flume
Processamento em tempo real

geradores de dados > source > channel > sink (destino) > armazenamento

unidade de dado: evento

11:39 comando flume-ng

A04-P05
Storm
sistema de computação distribuída em tempo real

arquitetura mestre-trabalhador

Nimbus gerencia os trabalhadores

Spout: entrada de dados
Bolt: processamento e entrega

um bolt pode entregar dados para outro bolt

cada bolt pode executar várias tarefas ao mesmo tempo, que podem ser agrupadas
All grouping: os dados são replicados para todas as tarefas
None grouping ou Shuffle grouping: dados são distribuidos aleatóriamente para as tarefas
Fields grouping: um campo no dado diz qual tarefa vai processá-lo
Direct grouping: a origem do dado define qual tarefa vai processá-lo

Zookeeper gerencia os Nimbus e os processos trabalhadores. Se um parar de funcionar ele ativa outro.

A04-P06
Flink
processamento de fluxos distribuídos

fluxo ilimitados ou limitados.
ilimitado não tem fim determinado

comunicação em protocolo REST

Fluxos, estados e tempo

fluxo é uma entrada de dado
estado informações armazenada entre eventos
tempo instante em que um evento é criado

APIs
Process functions: controla estados e tempos
DataStream: processamento usando MapReduce e ..Data 
SQL table: consulta sql

A10
Ferramentas: Kafka, Flume, Storm, Flink

Kafka
Publish/subscribe
comandos
Exemplo: separa palavras e conta

Flume
source/channel/sync
comandos
Exemplo de log

Storm
executa sobre o YARN
stream/Spouts/Bolts
comandos
exemplo de contagem de palavras

Flink
Se conecta a vários sistemas de arquivos e banco de dados: HDFS, Cassandra, Kafka, Redis, Elasticsearch ...
comandos
exemplo de contagem de palavras

A05-P01
Spark

A05-P02
A05-P03
A05-P04
A05-P05
A05-P06

A11

A06-P01

A12



